# Improved TritonBench evaluation framework

### Dependancy installation
- Install requirements as `pip install -r requirements.txt`

### Running evaluation
- See `check_correctness.py` for the use case.
- You can run call and execution accuracy evalution as 

`HIP_VISIBLE_DEVICES=0 python check_correctness.py -f PATH_TO_FILE_OR_FOLDER -o OUTPUT_FILE_NAME`

 `PATH_TO_FILE_OR_FOLDER` this can be a folder with multiple `*.json` files generated by an LLM or just a single `.json` file as input. `OUTPUT_FILE_NAME` is the output file name where log for each kernel evaluation is stored.
- Please ensure to use the TritonBench data provided in this repo.
- Please ensure to use the `TritonBench_G_comp_alpac_v1_fixed_with_difficulty.json` file for you generation experiments and save file name and difficulty for each kernel with generation response. This makes evaluation extremely easy.

### Issues with existing TritonBench evaluation framework
1. `1_exec_acc.py` file in TritonBench did not accurately compare the outputs of two Triton files.
1. The execution was purely done using subprocess call for both generated and ground truth files.
1. The seed consistancy is violated.
1. The outputs of the two Triton runs are compared using stdout string comparison, which is not always correct.
1. Around ground truth 150 files do not `print(result_gold)` line, hence the eval framework is essentially comapring the two null strings.
1. Some of the ground truth files (e.g. `context_attn_bloom.py`) does not even have `result_gold = test_*()` line at the end. So the call accuracy run using this file `0_call_acc.py` just blindly assumes that the call was success.

### We have fixed these issues as follows:
1. Use `torch.allclose` to compare two runs (ground truth and generated).
1. Fix ground truth files to include `result_gold = test_*()`.
1. Ensure consistent seed across files.


For now the performance measurement from TritonBench appears to be correct and we will continue to use that for our speedup and efficiency measurements.

#### Help/support/contribute:
Please raise github issue or PR for any issues/help or contributions!